<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Faust architecture: Differentiable DSP in Faust</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Faust architecture
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.8 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('md_architecture_2autodiff_2README.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Differentiable DSP in Faust</div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="autotoc_md41"></a></p><ul>
<li>Introduction<ul>
<li>Motivation</li>
<li>Differentiable Faust programs</li>
<li>Gradient descent in autodiff.cpp</li>
</ul>
</li>
<li>Faust Installation</li>
<li>Compiling an autodiff example</li>
<li>Running an autodiff example</li>
<li>Verifying via finite differences</li>
<li>Status of derivative implementations</li>
<li>Outlook</li>
</ul>
<h1><a class="anchor" id="autotoc_md42"></a>
Introduction</h1>
<h2><a class="anchor" id="autotoc_md43"></a>
Motivation</h2>
<p>With increasing interest in machine learning, differentiable programming, a key component in implementations of <em>gradient descent</em>, has become a hot topic in recent years. Python libraries such as PyTorch and JAX provide APIs for automatic differentiation of primitive functions, and the Swift language has introduced (limited) support for autodiff as a first-class language feature (see Swift's <a href="https://github.com/apple/swift/blob/main/docs/DifferentiableProgramming.md">differentiable programming manifesto</a>).</p>
<p>In the audio domain, pioneering work in differentiable DSP by Google's Magenta team (<a href="https://github.com/magenta/ddsp">magenta/ddsp</a>) demonstrated timbre transfer via gradient descent, based on differentiable implementations of functions supporting an array of audio synthesis and signal processing routines. More generic differentiable DSP has been demonstrated by <a href="https://github.com/khiner/jaxdsp/">jaxdsp</a>, and, with specific applicability to <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a>, David Braun's <a href="https://github.com/DBraun/DawDreamer">DawDreamer</a> project transpiles <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> code to Python to take advantage of the autodiff functionality provided by JAX.</p>
<p><a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a>, as an audio DSL, presents an interesting opportunity to implement native differentiable programming for audio-specific applications. Implemented effectively in the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler, differentiable DSP could benefit all available backends, and differentiable <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> algorithms could thus be deployed on all possible targets, from FPGA to the web. The <code>autodiff</code> architecture files, and associated modifications to the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler, facilitate this implementation and support parameter optimisation problems based on automatic differentiation and gradient descent.</p>
<h2><a class="anchor" id="autotoc_md44"></a>
Differentiable Faust programs</h2>
<p>Using <code>[diff:on]</code> or <code>[diff:1]</code> parameter metadata, and the <code>-diff</code> flag to the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler, it is possible to create differentiable DSP algorithms. <code>diff</code> metadata indicates a parameter with respect to which differentiation should be carried out, and can be applied to <code>hslider</code>, <code>vslider</code>, <code>nentry</code>, <code>button</code>, and <code>checkbox</code> <a class="el" href="structUI.html">UI</a> elements.</p>
<p>Forward mode autodiff is carried out as a signal stage transformation in the <code>SignalAutoDifferentiate</code> class (see <a href="../../compiler/transform/sigPromotion.cpp">sigpromotion.cpp</a>), with derivative expressions for math.h equivalent primitives added in their respective <a href="../../compiler/extended">classes</a>. With the exception of the recursive operator <code>~</code>, derivatives for all of <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a>'s basic and C-equivalent primitives are defined. See below for an overview of the status of derivative implementations.</p>
<hr  />
<p>Consider the following differentiable <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> algorithm, <code>gain.dsp</code>:</p>
<div class="fragment"><div class="line">gain = hslider(&quot;gain [diff:1]&quot;, .5, 0, 1, .001);</div>
<div class="line"> </div>
<div class="line">process = _*(gain);</div>
</div><!-- fragment --><p>which can be represented mathematically as $y = gx$, where $y$ is the output signal, $x$ the input signal, and $g$ the value of the gain parameter.</p>
<p>Compiling this algorithm with <code>faust gain.dsp</code> produces a <code>compute</code> method of the following form:</p>
<div class="fragment"><div class="line"> ++</div>
<div class="line"><span class="keyword">virtual</span> <span class="keywordtype">void</span> compute(<span class="keywordtype">int</span> count, FAUSTFLOAT** RESTRICT inputs, FAUSTFLOAT** RESTRICT outputs) {</div>
<div class="line">    FAUSTFLOAT* input0 = inputs[0];</div>
<div class="line">    FAUSTFLOAT* output0 = outputs[0];</div>
<div class="line">    <span class="keywordtype">float</span> fSlow0 = float(fHslider0);</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i0 = 0; i0 &lt; count; i0 = i0 + 1) {</div>
<div class="line">            output0[i0] = FAUSTFLOAT(fSlow0 * <span class="keywordtype">float</span>(input0[i0]));</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The algorithm can be differentiated with respect to its parameter, <code>gain</code>, by calling the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler with the <code>-diff</code> flag:</p>
<div class="fragment"><div class="line">faust -diff gain.dsp</div>
</div><!-- fragment --><p>The result is a new DSP algorithm whose output is the derivative of the original algorithm with respect to <code>gain</code>. In the case of this simple example, the compiler applies the product rule:</p>
<p>$$ \begin{align*} \frac{dy}{dg} &amp;= v\frac{du}{dx} + u\frac{dv}{dx}, \quad u = g, v = x \ &amp;= x\frac{d}{dg}(g) + g\frac{d}{dg}(x) \ &amp;= x(1) + g(0) \ &amp;= x. \end{align*} $$</p>
<p>This is the resulting <code>compute</code> method:</p>
<div class="fragment"><div class="line"> ++</div>
<div class="line"><span class="keyword">virtual</span> <span class="keywordtype">void</span> compute(<span class="keywordtype">int</span> count, FAUSTFLOAT** RE&amp;=STRICT inputs, FAUSTFLOAT** RESTRICT outputs) {</div>
<div class="line">    FAUSTFLOAT* input0 = inputs[0];</div>
<div class="line">    FAUSTFLOAT* output0 = outputs[0];</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i0 = 0; i0 &lt; count; i0 = i0 + &amp;=1) {</div>
<div class="line">            output0[i0] = FAUSTFLOAT(<span class="keywordtype">float</span>(input0[i0]));</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler generates this output by performing <em>automatic differentiation</em> (<em>forward</em>, or <em>tangent</em> mode <b>autodiff</b>, to be precise) as a signal stage transformation of the input DSP algorithm.</p>
<p>Provide the <code>-d|--details</code> flag to the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler to see detailed output of the differentiation process.</p>
<p>E.g. for a differentiable gain slider, computation of the derivative is reported as follows:</p>
<div class="fragment"><div class="line">$ faust -d -diff gain.dsp</div>
<div class="line">process = _,hslider(&quot;gain [diff:1]&quot;, 0.5f, 0.0f, 1.0f, 0.001f) : *;</div>
<div class="line">...</div>
<div class="line">&gt;&gt;&gt; Differentiate wrt. hslider(&quot;gain [diff:1]&quot;,0.5f,0.0f,1.0f,0.001f)</div>
<div class="line"> </div>
<div class="line">    x: IN[0]    y: hslider(&quot;gain [diff:1]&quot;,0.5f,0.0f,1.0f,0.001f)   op: MUL</div>
<div class="line"> </div>
<div class="line">        UI element: hslider(&quot;gain [diff:1]&quot;,0.5f,0.0f,1.0f,0.001f)</div>
<div class="line"> </div>
<div class="line">        DERIVATIVE: 1.0f</div>
<div class="line"> </div>
<div class="line">        Input: IN[0]</div>
<div class="line"> </div>
<div class="line">        DERIVATIVE: 0.0f</div>
<div class="line"> </div>
<div class="line">    DERIVATIVE: 0.0f*hslider(&quot;gain [diff:1]&quot;,0.5f,0.0f,1.0f,0.001f)+IN[0]*1.0f</div>
<div class="line">...</div>
</div><!-- fragment --><p>For algorithms with multiple differentiable parameters, i.e. a vector of parameters $\mathbf{p}$, the differentiated DSP instance possesses a number of output channels equal to the number of parameters, each output representing an element in a vector of partial derivatives:</p>
<p>$$ \frac{\partial y}{\partial \mathbf{p}} = \begin{bmatrix} \frac{\partial y}{\partial p_1} \frac{\partial y}{\partial p_2} \cdots \frac{\partial y}{\partial p_N} \end{bmatrix}^T $$</p>
<p>For example, given an algorithm consisting of a differentiable gain control and DC offset, $y = p_{\text{gain}}x + p_{\text{dc}}$:</p>
<div class="fragment"><div class="line">gain = hslider(&quot;gain [diff:1]&quot;, .5, 0, 1, .001);</div>
<div class="line">dc = hslider(&quot;dc [diff:1]&quot;, .25, -.5, .5, .001);</div>
<div class="line"> </div>
<div class="line">process = _*gain,dc : +;</div>
</div><!-- fragment --><p>the resulting <code>compute</code> method is:</p>
<div class="fragment"><div class="line"> ++</div>
<div class="line"><span class="keyword">virtual</span> <span class="keywordtype">void</span> compute(<span class="keywordtype">int</span> count, FAUSTFLOAT** RESTRICT inputs, FAUSTFLOAT** RESTRICT outputs) {</div>
<div class="line">    FAUSTFLOAT* input0 = inputs[0];</div>
<div class="line">    FAUSTFLOAT* output0 = outputs[0];</div>
<div class="line">    FAUSTFLOAT* output1 = outputs[1];</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i0 = 0; i0 &lt; count; i0 = i0 + 1) {</div>
<div class="line">        output0[i0] = FAUSTFLOAT(1.0f);</div>
<div class="line">        output1[i0] = FAUSTFLOAT(<span class="keywordtype">float</span>(input0[i0]));</div>
<div class="line">    }</div>
<div class="line">}</div>
</div><!-- fragment --><p>The first output channel represents the partial derivative with respect to the <code>dc</code> parameter:</p>
<p>$$ \frac{\partial y}{\partial p_{\text{dc}}} = 1. $$</p>
<p>The second output channel is the partial derivative with respect to <code>gain</code>:</p>
<p>$$ \frac{\partial y}{\partial p_{\text{gain}}} = x. $$</p>
<h2><a class="anchor" id="autotoc_md46"></a>
Gradient descent in the autodiff architecture file</h2>
<p>Gradient descent is implemented in the architecture file, <a href="./autodiff.cpp">autodiff.cpp</a>. Input, ground truth, learnable and differentiated DSP instances are compiled dynamically at runtime and a <code>dsp_paralellizer</code> instance used to compute their output in parallel (see Compiling an autodiff example).</p>
<p>An output signal, $s_o(\mathbf{p}_k)$, produced by a DSP algorithm with a vector of <em>learnable parameters</em>, $\mathbf{p}$ (at iteration $k$), is compared, by way of a <b>loss function</b>, $\mathcal{L}$, with that of a <em>ground truth</em> output signal, $s_o(\mathbf{\hat{p}})$, governed by <em>hidden parameters</em> $\mathbf{\hat{p}}$. A <b>gradient function</b> uses the partial derivatives, $\nabla s_o(\mathbf{p}_k)$, produced by the differentiated DSP algorithm to compute $\frac{\partial \mathcal{L}}{\partial \mathbf{p}_k}$, the derivative of the loss function with respect to the vector of parameters; for each parameter, the function produces a <em>gradient</em>, $\frac{\partial \mathcal{L}}{\partial p_{i,k}}$, which, scaled by a <em>learning rate</em>, $\alpha$, is used to produce an updated parameter value:</p>
<p>$$ \mathbf{p}_{k+1} = \mathbf{p}_k - \alpha\frac{\partial \mathcal{L}}{\partial \mathbf{p}_k}. $$</p>
<div class="fragment"><div class="line">flowchart LR</div>
<div class="line">A[Input DSP] --&gt; B[Ground Truth DSP]</div>
<div class="line">A --&gt; C[Learnable DSP]</div>
<div class="line">A --&gt; D[Differentiated DSP]</div>
<div class="line">B --&gt; E{{Loss\nFunction}} </div>
<div class="line">C --&gt; E</div>
<div class="line">G((Learning\nRate)) -.-&gt; F</div>
<div class="line">B --&gt; F{{Gradient\nFunction}}</div>
<div class="line">E -.-|&quot;(derivative)&quot;| F</div>
<div class="line">C --&gt; F</div>
<div class="line">D &amp; D &amp; D --&gt; F</div>
<div class="line">F &amp; F &amp; F -.-&gt; H((&quot;(Learnable DSP\nparameters)&quot;))</div>
</div><!-- fragment --><p>This process is repeated iteratively with the aim of minimising the value returned by the <br  />
 loss function, i.e. until the learnable parameters approximate the hidden ones.</p>
<h3><a class="anchor" id="autotoc_md47"></a>
Caveats</h3>
<ul>
<li>at present, support is only provided for provision of a single ground truth signal, i.e. there is no way to provide batches of training data.</li>
<li>loss is calculated in the time domain on a per-sample basis, so, for gradient descent to work, the input signal must be deterministic, and the same input signal is delivered to each of the ground truth, learnable, and differentiated DSP instances.</li>
<li>in order to operate sample-by-sample, the autodiff architecture file uses a dummy audio driver, with a buffer size of 1, in order to be able to make per-sample parameter updates.<ul>
<li>at present, autodiff in <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> is an exploratory project, and not a platform for generating sound in real time.</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md48"></a>
Faust Installation</h1>
<p>The autodiff architecture file and verifier use <a href="https://faustdoc.grame.fr/manual/embedding/#libfaust-with-llvm-backend-api">libfaust</a> and <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a>'s LLVM backend to compile DSP files dynamically at runtime. To support this, <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> must be compiled with inclusion of the LLVM backend. This is most easily (if not quickly) achieved by building <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> with all backends and targets:</p>
<div class="fragment"><div class="line">cd ../../build</div>
<div class="line">make BACKENDS=all.cmake TARGETS=all.cmake</div>
<div class="line">sudo make install</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md49"></a>
Compiling an autodiff example</h1>
<p>autodiff.cpp differs from other architecture files (and is not yet a <em>true</em> <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> architecture file) in that, rather than being populated by the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler via the <code>-a</code> flag, it is intended to be compiled directly (or via the shell script <a href="./autodiff.sh">autodiff.sh</a>).</p>
<p>To compile, <code>llvm-config</code> should be used to generate flags for the appropriate LLVM library to link to.</p>
<div class="fragment"><div class="line">outputdir=~/tmp/faust-autodiff</div>
<div class="line">c++ -std=c++14 autodiff.cpp $(faust -libdir)/libfaust.a \</div>
<div class="line">  $(llvm-config --ldflags --libs all --system-libs) \</div>
<div class="line">  -o $outputdir/autodiff_example</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md50"></a>
Missing library &lt;tt&gt;-lzstd&lt;/tt&gt;</h2>
<p>For LLVM 16 on Mac OS X, your c++ compiler may not be able to find the <a href="https://facebook.github.io/zstd/">zstd</a> library. The easiest remedy is to install it via homebrew:</p>
<div class="fragment"><div class="line">brew install zstd</div>
</div><!-- fragment --><p>and adjust the call to <code>c++</code> as follows:</p>
<div class="fragment"><div class="line">c++ -std=c++14 autodiff.cpp $(faust -libdir)/libfaust.a \</div>
<div class="line">  $(llvm-config --ldflags --libs all --system-libs) \</div>
<div class="line">  -L/opt/local/lib \</div>
<div class="line">  -o $outputdir/autodiff_example</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md51"></a>
Running an autodiff example</h1>
<p>Run the compiled executable, specifying the following dsp files:</p>
<ul>
<li><code>--input</code> &mdash; the signal to run through the ground truth and differentiable dsp algorithms;<ul>
<li>for differentiable algorithms with no input, any valid <code>.dsp</code> file will do;</li>
</ul>
</li>
<li><code>--gt</code> &mdash; the ground truth dsp;</li>
<li><code>--diff</code> &mdash; the differentiable dsp to be trained/optimised.</li>
<li>it is also possible to specify the loss function to use via the optional <code>-lf|--lossfunction &lt;function&gt;</code> flag. Implemented loss functions are:<ul>
<li><code>l1</code> &mdash; L-1 norm;</li>
<li><code>l2</code> (default) &mdash; L-2 norm.</li>
</ul>
</li>
<li>supply <code>-lr|--learningrate &lt;rate&gt;</code> to set a floating-point number to use as the learning rate (if not provided, the default value, 0.1, is used).</li>
</ul>
<div class="fragment"><div class="line">outputdir=~/tmp/faust-autodiff</div>
<div class="line">cd $outputdir || exit</div>
<div class="line">examplesdir=$(faust --archdir)/examples/autodiff</div>
<div class="line">./autodiff_example --input $examplesdir/noise.dsp \</div>
<div class="line">  --gt $examplesdir/gain/gt.dsp \</div>
<div class="line">  --diff $examplesdir/gain/diff.dsp \</div>
<div class="line">  -lf l2 \</div>
<div class="line">  -lr 0.1</div>
</div><!-- fragment --><blockquote class="doxtable">
<p>&zwj;The above commands are encapsulated in <a href="autodiff.sh">autodiff.sh</a>.</p>
<p></p>
</blockquote>
<p>&gt;<code>shell &gt;./autodiff.sh &lt;example_name&gt; &gt;</code> </p><blockquote class="doxtable">
<p>&zwj; </p>
</blockquote>
<p>&gt;For a list of available examples, execute <code>./autodiff.sh</code> without any arguments.</p>
<p>Running the executable displays numerical output describing the gradient descent process. For the <code>one_zero</code> example:</p>
<div class="fragment"><div class="line">Learning rate: 0.1</div>
<div class="line">Sensitivity: 1e-07</div>
<div class="line">...</div>
<div class="line">Learnable parameter: b1, value: 0.5</div>
<div class="line"> </div>
<div class="line">-----------------------------------------------------------------</div>
<div class="line"> Iter   Ground truth      Learnable           Loss             b1</div>
<div class="line">-----------------------------------------------------------------</div>
<div class="line">    1  -0.9990000129  -0.9990000129      0.000e+00              -</div>
<div class="line">    2  -1.9870100021  -1.4975000620   0.2396199852   0.5978040695</div>
<div class="line">    3  -1.9850200415  -1.5936084986   0.1532029957   0.6759297848</div>
<div class="line">    4  -1.9830299616  -1.6699019670   0.0980491415   0.7383674979</div>
<div class="line">    5  -1.9810400009  -1.7304140329   0.0628133789   0.7882921696</div>
<div class="line">  ...</div>
</div><!-- fragment --><p>The executable generates a csv file containing the loss and parameter values at each iteration. To plot this data, copy <a href="./plot.py">plot.py</a> to your output directory and run <code>python3 plot.py</code> (requires that matplotlib is installed globally).</p>
<p><img src="loss_example.png" alt="Loss plot example" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md52"></a>
Verification via finite differences</h1>
<p>The output of a differentiated DSP algorithm can be compared with a numerical derivative computed via finite differences. This can be achieved with the <code><a class="el" href="classautodiffVerifier.html">autodiffVerifier</a></code> utility, which takes a differentiable DSP algorithm, and, for each parameter $p$, and a perturbation of that parameter $\epsilon$, computes the delta between autodiffed output and finite difference output:</p>
<p>$$ \delta = \left|y'(p) - \frac{y(p + \epsilon) - y(p)}{\epsilon}\right| $$</p>
<p>To build the verifier, copy the required files and compile <code>autodiffVerifier.cpp</code>:</p>
<div class="fragment"><div class="line">outputdir=~/tmp/faust-autodiff</div>
<div class="line">mkdir -p $outputdir</div>
<div class="line">c++ -std=c++14 autodiffVerifier.cpp $(faust -libdir)/libfaust.a \</div>
<div class="line">  $(llvm-config --ldflags --libs all --system-libs) \</div>
<div class="line">  -o $outputdir/autodiff_verify</div>
</div><!-- fragment --><p>Then run the resulting executable, specifying input and differentiable DSP files, and an optional value for $\epsilon$ (default 1e-3).</p>
<div class="fragment"><div class="line">outputdir=~/tmp/faust-autodiff</div>
<div class="line">cd $outputdir || exit</div>
<div class="line">examplesdir=$(faust --archdir)/examples/autodiff</div>
<div class="line">./autodiff_verify --input $examplesdir/noise.dsp \</div>
<div class="line">  --diff $examplesdir/gain_dc/diff.dsp \</div>
<div class="line">  --epsilon 1e-3</div>
</div><!-- fragment --><p>The differentiable DSP algorithm is compiled in (at least) three forms:</p><ul>
<li>unmodified: $y(\mathbf{p})$</li>
<li>with $\epsilon$ applied to each adjustable parameter in turn<ul>
<li>for multiple parameters, as many copies are made of the DSP as there are parameters, each copy having one parameter increased by $\epsilon$</li>
<li>for the $k^\text{th}$ parameter: $y(\dots,p_k + \epsilon,\dots)$</li>
</ul>
</li>
<li>automatically differentiated: $y'(\mathbf{p})$</li>
</ul>
<p>These are used to compute $\delta$ for each parameter. Additionally, each delta is compared with its corresponding channel in the autodiff algorithm (which represents a partial derivative with respect to that parameter), and relative error reported.</p>
<div class="fragment"><div class="line">--------------------------------------------------------------------------------</div>
<div class="line"> Iter          Param       Autodiff    Finite diff        |delta|     Rel. error</div>
<div class="line">--------------------------------------------------------------------------------</div>
<div class="line">    1             dc   1.0000000000   0.9999870658      1.293e-05        0.001 %</div>
<div class="line">                gain   0.0000057486   0.0000298023      2.405e-05      418.428 %</div>
<div class="line">    2             dc   1.0000000000   0.9999870658      1.293e-05        0.001 %</div>
<div class="line">                gain  -0.3448459506  -0.3448426425      3.308e-06        0.001 %</div>
<div class="line">    3             dc   1.0000000000   0.9999870658      1.293e-05        0.001 %</div>
<div class="line">                gain  -0.6951856613  -0.6951763630      9.298e-06        0.001 %</div>
<div class="line">...</div>
<div class="line">   98             dc   1.0000000000   0.9999870658      1.293e-05        0.001 %</div>
<div class="line">                gain  -0.5611450076  -0.5611385703      6.437e-06        0.001 %</div>
<div class="line">   99             dc   1.0000000000   0.9999274611      7.254e-05        0.007 %</div>
<div class="line">                gain   0.8623053432   0.8622407317      6.461e-05        0.007 %</div>
<div class="line">  100             dc   1.0000000000   0.9999870658      1.293e-05        0.001 %</div>
<div class="line">                gain  -0.5016716123  -0.5016651750      6.437e-06        0.001 %</div>
<div class="line"> </div>
<div class="line">Parameter: dc</div>
<div class="line">===============================</div>
<div class="line">         Mean delta:  1.989e-05</div>
<div class="line"> Standard deviation:  1.679e-05</div>
<div class="line"> </div>
<div class="line">Parameter: gain</div>
<div class="line">===============================</div>
<div class="line">         Mean delta:  1.228e-05</div>
<div class="line"> Standard deviation:  1.216e-05</div>
</div><!-- fragment --><p>Note that the high relative error for <code>gain</code> at iteration 1 is due to the very low amplitude of the first sample produced by <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a>'s <code>no.noise</code> function.</p>
<h1><a class="anchor" id="autotoc_md53"></a>
Status of derivative implementations</h1>
<h3><a class="anchor" id="autotoc_md54"></a>
C-equivalent primitives</h3>
<ul>
<li>[x] Arithmetical operations <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>^</code>, <code>%</code><ul>
<li>derivative of <code>f % g</code> ignores the case where $f = kg, k \in \mathbb{Z}$ and pretends that the function is smooth</li>
</ul>
</li>
<li>[x] Bitwise operations <code>&amp;</code>, <code>|</code>, <code>xor</code>, <code>&lt;&lt;</code>, <code>&gt;&gt;</code><ul>
<li>the piecewise derivatives of these functions are zero <em>almost</em> everywhere, so their derivatives are defined as zero everywhere.</li>
</ul>
</li>
<li>[x] Logical comparisons <code>&lt;</code>, <code>&gt;</code>, <code>&lt;=</code>, <code>&gt;=</code>, <code>!=</code><ul>
<li>derivatives also defined as zero everywhere.</li>
</ul>
</li>
</ul>
<h3><a class="anchor" id="autotoc_md55"></a>
math.h-equivalent primitives</h3>
<ul>
<li>[x] All functions besides <code>atan2</code><ul>
<li>derivative of <code>abs(x)</code> is defined as zero at $x = 0$</li>
<li>derivatives of <code>acos(x)</code> and <code>asin(x)</code> are only defined over the domain $x \in \mathbb{R} : -1 &lt; x &lt; 1$</li>
<li>derivative of <code>tan(x)</code> doesn't behave well for $x = (2n - 1)\pi/2, n \in \mathbb{Z}$</li>
<li>derivatives of <code>ceil</code> and <code>floor</code>, <code>rint</code>, <code>round</code> are defined as zero everywhere</li>
<li><code>fmod</code> and <code>remainder</code> are defined like <code>f % g</code> above</li>
<li><code>log(x)</code> and <code>log10(x)</code> don't behave well at $x = 0$</li>
</ul>
</li>
<li>[ ] <code>atan2</code></li>
</ul>
<h3><a class="anchor" id="autotoc_md56"></a>
Other primitives and expressions</h3>
<ul>
<li>[x] Time operators <code>mem</code>, &lsquo;&rsquo;<code>,</code>&lt;tt&gt;<ul>
<li>the derivative of&lt;tt&gt;is implemented as convolution with a differentiated square pulse of single sample duration; this narrow support, coupled with per-sample time domain loss, means that, if differentiating with respect to a dynamic delay, the derivative may fail to capture the dynamic behaviour, in which case gradient descent will fail.</li>
</ul>
</li>
<li>[ ]rdtable<code>,</code>rwtable<code></code></li>
<li><code>[ ]</code>soundfile<code>,</code>waveform<code></code></li>
<li><code>[ ]</code>select2<code>,</code>select3<code></code></li>
<li><code>[ ] Foreign expressions</code></li>
<li><code>[ ] Recursion</code>~`<ul>
<li>see Outlook for further discussion of the difficulty of implementing a derivative of a recursive expression at the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> compiler's signal stage.</li>
</ul>
</li>
</ul>
<h1><a class="anchor" id="autotoc_md57"></a>
Outlook</h1>
<h3><a class="anchor" id="autotoc_md58"></a>
Autodiff modes</h3>
<p>Algorithms are differentiated using forward mode autodiff only. This is acceptable for algorithms with small numbers of differentiable parameters, but for algorithms with many parameters this may be computationally unviable. As the <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a> Autodiff project moves beyond an exploratory stage, it will be important to consider implementing reverse mode autodiff too.</p>
<h3><a class="anchor" id="autotoc_md59"></a>
Loss computation</h3>
<p>Currently, loss and gradient descent are calculated in the time domain on a per-sample basis. This works for simple parameter optimisation problems such as a learnable gain control acting on deterministic input, but more demanding problems will require the development of better measures of loss. <code>magenta/ddsp</code> describes spectral loss as the <a href="https://github.com/magenta/ddsp/blob/7e0a39420f3bd87d9efd54cf0d36f4e258311340/ddsp/losses.py#L132"><em>bread and butter of comparing two audio signals</em></a>; it will be an important step to implement frequency-domain loss functions to support sophisticated machine learning approaches in <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a>.</p>
<h3><a class="anchor" id="autotoc_md60"></a>
Recursion</h3>
<p>A simple recursive DSP algorithm $y[n]$, dependent on continuous parameter $p$, may be expressed as a composition of $f(u_1, u_2, u_3)$, the non-recursive component, and $g(v_1, v_2)$, the recursive component:</p>
<p>$$ y(p)[n] = f(p, x[n], g(p, y(p)[n-1])). $$</p>
<p>Its derivative with respect to $p$ is:</p>
<p>$$ \frac{d}{dp}y(p)[n] = \frac{\partial}{\partial u_1}f + \frac{\partial}{\partial u_3}f\left( \frac{\partial}{\partial v_1}g + \frac{\partial}{\partial v_2}g\frac{\partial}{\partial p}y(p)[n-1] \right). $$</p>
<p>Due to the way that recursion is expressed symbolically at the signal stage, however, it is not straightforward to separate the elements of the body of the recursion in order to calculate the required partial derivatives. Consequently, a derivative of recursion has not yet been implemented, which is of course a significant drawback, given the ubiquity of recursive algorithms in signal processing and audio synthesis.</p>
<p>Decomposition of the body of a recursive expression may be possible at the <b>box stage</b>, however; further work on this project should focus on establishing whether this is indeed the case.</p>
<p>An additional potential advantage of moving autodiff to the box stage is that differentiation could become a part of <a class="el" href="classFaust.html" title="Alchemy DSP.">Faust</a>'s core syntax and box algebra.</p>
<h3><a class="anchor" id="autotoc_md61"></a>
Putting autodiff to practical use</h3>
<p>As described, gradient descent is carried out on a per-sample basis, which is only possible with a buffer size of 1 sample, facilitated by the use of a dummy audio driver. This means gradient descent, in its current implementation is of illustrative, but limited practical use. Coupled with more sophisticated measures of loss, computed for windowed chunks of output produced by the learnable algorithm, it should be possible (and indeed an important aim for further development of this work) to use a real audio driver and optimise parameters in real time. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.8 </li>
  </ul>
</div>
</body>
</html>
